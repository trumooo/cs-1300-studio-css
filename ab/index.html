<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Responsive Redesign</title>
    <link rel="stylesheet" href="styles.css" />
</head>
<body>
    <header>
        <h1>Comparing Two Websites</h1>
    </header>
    <main>
        <div class="note">
            <h2>A Case Study into A/B Testing</h2>
            <p>It is easy to know when a website is bad. However, it is very hard to know what specifically makes it bad. It is even harder to know which of two websites is better.</p>
            <a>However, this becomes a lot easier with <b>a/b testing</b>.</a>
            <hr>
            <p>This journal entry will start with a case study overview, then move to website analysis, proceed to a statistical summary, and analyze real user data.</p>
        </div>
        <div class="section-border">
            <h3>Getting Started</h3>
            <p>I wanted to see how easy it is to A/B test. This term has always felt a little abstract and elusive, so I wanted to know what exact conclusions you can draw from it and when you should be using it.</p>
            <p>First, I needed a website. Luckily, this was all part of a class project, so I was given one to start with. This serves as our A-site. It is a website meant to help you book doctor appointments.</p>
            <p>Here is an image of the website I was given, which we will just call "A".</p>
            <img class="image" alt="website with pale buttons and hard to read text" src="./assets/a.png"/>
            <p>I was also given an objective to measure for A.</p>
        </div>
        <div class="section-flat">
            <h3>The Objective</h3>
            <p>Users were supposed to register for an appointment with Adam Ng at Morristown Medical Center on April 23, 2024.</p>
            <p>This meant that they had to click on this specific button to succeed. Clicking another button resulted in a failure, and clicking on some other page element was called a misclick.</p>
            <img class="image-small" alt="website with an arrow pointing to specific button" src="./assets/a_highlighted.png"/>
            <p>In all, 23 users accessed the page; they were tasked to achieve the objective. During this time, their mouse movement, time on page, and clicks were recorded.</p>
        </div>
        
        <h1>Starting to Redesign</h1>
        <p>Now, I had a website, an objective, and some user data. All I needed was something to compare this to. I sought to create a different version of A. However, before doing this, I analyzed the core faults with A.</p>
        <div class="section-shadow">
            <h3>The Problems with A</h3>
            <h4>1. Too little contrast between the button's text and background color.</h4>
            <h4>2. The "See Appointment" and "Schedule Appointment" buttons are identical.</h4>
            <h4>3. The dates are not in chronological order.</h4>
            <h4>4. The locations are not clearly separated or filterable.</h4>
            <h4>5. The doctors are not clearly separated or filterable.</h4>
            <p>These visual design choices result in site A having poor visibility and accessibility.</p>
        </div>
        <div class="section-border">
            <h1>Creating B</h1>
            <p>A/B testing works best when you test one or a few specific elements at a time. This allows you to see what exact change made the difference, rather than just knowing something changed.</p>
            <p>Thus, I knew I only wanted to make one or two changes to my alternative version of A, which we will just call "B".</p>
            <p>I decided that the hard-to-read text was the most significant limitation on an individual's success rate, so I made changes to emphasize this when making my edits.</p>
            <p>Specifically, I tried to focus on making the schedule and see appointments buttons both readable and slightly more distinct (using a drop shadow and different background for the schedule appointment button). I also went ahead and increased the font thickness for the dates, so that people could more easily see the date of each appointment.</p>
            <img class="image" alt="website with schedule appointment buttons and see appointment buttons on different color backgrounds" src="./assets/b.png"/>
            <p>The overall theme for my B was to improve readability.</p>
        </div>
        <h1>The Data</h1>
        <p>In all, 20 people interacted with site B. They all attempted the same objective as the users from site A. Now, I want to see which website is better.</p>
        <p>On the left is the data for site A, and the new data from site B is on the right.</p>
        <img class="image-small" alt="data sheet for A users" src="./assets/a_data.png"/> <a></a><img class="image-small" alt="data sheet for B users" src="./assets/b_data.png"/>
        <p>There is a lot here, so I'll break it down further.</p>
        <h3>There are three main data categories that I will be investigating to statistically determine the better website:</h3>
        <h4>1. Did the user misclick? (known as "did_misclick")</h4>
        <h4>2. How much did the user move their mouse? (known as "mouse_move_distance")</h4>
        <h4>3. How long was the user on the page before completing the objective? (known as "time_on_page")</h4>
        <p>Since we are comparing two websites, we don't really need to focus too much on the units for these data points, rather just that they are consistent from website A to B. This has one notable exception of "did_misclick" which is a binary option. We will put a pin in this idea, and explain it later.</p>
        <a><b>My main goal is to determine which of these three statistics are significantly different between site B and A.</b> Whenever possible, I want to determine which of B's statistics are significantly less than A's statistics.</a>
        <p>I will be using a statistical threshold of p=0.05. This means that all p-values less than 0.05 will be considered significant.</p>
        
        <div class="section-flat">
            <h2>Analysis Of Misclick Data:</h2>
            <p>This is a binary data point. Results are either TRUE or FALSE. This represents whether or not the user clicked on something before clicking the appointment button.</p>
            <p>For this statistical analysis, we want to prove that there is a significant difference between site A and B.</p>
            <p>This means that our <b>Null Hypothesis (H0)</b> is that there is no significant difference between the misclick rate for Site A and Site B.</p>
            <p>Our <b>Alternative Hypothesis (HA)</b> is that the edits made to Site B's buttons and styling caused a scientifically significant difference in the misclick rate for Site A and Site B.</p>
            <p>My <b>prediction</b> is that we will prove our HA because many stylistic and visual edits were made.</p>
            <p>I need to use a <b>chi-square test</b> to analyze the statistical difference between site A and B because misclick data is a binary flag.</p>
        </div>
        <div class="section-shadow">
            <h3>Misclick - Chi-square - Data Summary</h3>
            <img class="image-small" alt="graph showing misclick data" src="./assets/misclick.png"/>
            <p>The Degrees of Freedom for this test are one. This is based on the number of rows and columns of the data table. With a one and a significant threshold of p < 0.05, we can look at the chi-square distribution table to get a significance level of 3.841. All this means is that if our Chi^2 value is greater than 3.841, then we can reject our null hypothesis. The Chi^2 value was calculated to be 6.0634. <b>Thus, we can reject the null hypothesis. The edits made to site B caused a significant change in user misclick data.</b></p>
        </div>

    <hr>
    <div class="section-flat">
        <h2>Analysis Of Time Data:</h2>
        <p>This is a continuous data point. Results are in milliseconds. This represents how long the user was on the website before completing the objective.</p>
        <p>For this statistical analysis, we want to prove that users spent less time on site B than on site A. This would mean the new design was more efficient and clear. This was not possible for a binary data point; however, we can do it for continuous data types through a two-sample, one-tail t-test. Essentially, we are comparing two different sets of continuous variables and want to see if one group is significantly less than the other.</p>
        <p>This means that our <b>Null Hypothesis (H0)</b> is that there is no significant difference between the time spent on Site A and Site B.</p>
        <p>Our <b>Alternative Hypothesis (HA)</b> is that our edits made it so that users on site B needed significantly less time to complete the objective than users on Site A.</p>
        <p>My <b>prediction</b> is that we will prove our HA because many stylistic and visual edits were made, improving the text legibility of site B.</p>
    </div>
    <div class="section-shadow">
        <h3>Time Spent - Two Sample, One Sided T-test - Data Summary</h3>
        <img class="image-small" alt="graph showing time spent data" src="./assets/time.png"/>
        <p>The average time on page A is 8193.8 ms. The variance for page A is 6594762.168. The average time on page B is 22324.783 ms. The variance for page B is 234839182.451. We use these statistics to complete a T-test which gives us a Degrees of Freedom of 23.4156. The more degrees of freedom that a t-test has, the more the data-set distribution approaches normal. We also got a t-score of 4.353. This indicates a significant spread between the two groups. A positive number specifically means that Site B's time is less than site A's. Finally, we also got a p-value of 1-0.00011293. This is less than 1-0.05, so <b>we can reject the null hypothesis. The edits made to site B led users to spend significantly less time on the page than site A.</b></p>
    </div>
    
    <hr>
    <div class="section-flat">
        <h2>Analysis Of Mouse Movement Data:</h2>
        <p>This is a continuous data point. Results are in pixels. This represents how much the user moved their mouse before completing the objective.</p>
        <p>For this statistical analysis, we want to prove that users moved their mouse less on site B than on site A. We can use a two-sample, one-sided t-test for this. </p>
        <p><b>Null Hypothesis (H0)</b> is that there is no significant difference in mouse movement between Site A and Site B.</p>
        <p><b>Alternative Hypothesis (HA)</b> is that our edits made it so that users on site B moved their mouse significantly less than users on Site A.</p>
        <p>My <b>prediction</b> is that we will prove our HA because many stylistic and visual edits were made, making the users have to search less for their objective.</p>
    </div>
    <div class="section-shadow">
        <h3>Mouse Movement - Two Sample, One Sided T-test - Data Summary</h3>
        <img class="image-small" alt="graph showing mouse movement data" src="./assets/mouse.png"/>
        <p>The average movement on page A is 6471.423px. The variance for page A is 19773316.8. The average movement on page B is 2435.399 px. The variance for page B is 452799.514. We use these statistics to complete a T-test which gives us a Degrees of Freedom of 23.155. We also got a t-score of 4.297. This indicates a significant spread between the two groups. A positive number specifically means that Site B's movement is less than site A's. Finally, we also got a p-value of 1-0.0001327. This is less than 1-0.05, so <b>we can reject the null hypothesis. The edits made to site B led users to move their mouse significantly less than users of site A.</b></p>
    </div>
    <div class="section-border">
        <h1>Results:</h1>
        <p>In all, we rejected all of the null hypotheses. This shows that Site B is probably a better site than Site A when it comes to completing the assigned objective. That last bit is very important. We do not know any information about how sites A and B performed for other tasks. Some of the edits we made could have improved one task but greately worsened others. This is important to consider as we continue to work. In a real world scenario, this would only be the start! From here, many more alternatives could be tested. I believe that website B is the greater site because of the readability improvements. These further tests could show what exactly is the most readable or intuitive method of showing doctor appointments. Additionally, in further testing it is very likely that sometimes not all variables pass the null hypothesis. In these scenarios, it is up to the designer and team to figure out what the suitable next step is.   </p>
        <p>I really enjoyed this project because it gave me the ability to actually go ahead and complete something that I had only heard about. I was able to ground the theoretical into the practical! Now, I am just excited to get started on my next test!
        </p>
    </div>
    </main>
    
    <footer>
    </footer>
</body>
</html>
